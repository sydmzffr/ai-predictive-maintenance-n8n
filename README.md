# AI-Powered Predictive Maintenance Alerting System
This project demonstrates a complete, end-to-end system that uses a machine learning model to predict equipment failure and automatically sends alerts. A user can input machine sensor data through a web form, and if the AI model predicts a high risk of failure, an alert is dispatched to the relevant personnel. This serves as a practical example of operationalizing a data science model, moving it from a research environment (a Jupyter Notebook) into a live, interactive application using modern workflow automation and API microservices. 

# Core Technologies Used
Machine Learning: Python, scikit-learn, pandas
AI Model Serving: Flask (as a lightweight Python microservice)
Workflow Automation: n8n (Cloud version)
Secure Tunneling: ngrok (to expose the local Flask API to the internet)
Development Environment: Jupyter Notebook, Visual Studio Code

# Project Architecture
The system is designed with a decoupled, microservice-based architecture, allowing each component to operate independently. 
User Interface (n8n Form Trigger): A simple web form, automatically generated by n8n, serves as the user interface for inputting machine parameters.
Automation Engine (n8n Workflow): n8n orchestrates the entire process. It receives the form submission, calls the AI service, evaluates the prediction, and triggers alerts.
Secure Tunnel (ngrok): ngrok creates a secure public URL that forwards requests from the n8n cloud workflow to the Flask API running locally on the development machine.
AI Microservice (Flask API): A lightweight Python server that wraps the machine learning model. It exposes a single /predict endpoint that accepts machine data, runs it through the model, and returns a JSON prediction.
AI Model (.joblib file): The pre-trained scikit-learn pipeline, exported from a Jupyter Notebook, which contains all the necessary preprocessing steps and the trained logistic regression model.

# How It Works: Step-by-StepAn 
engineer or operator accesses the public n8n Form URL. 
They input the current machine parameters (Temperature, Speed, Torque, etc.) and submit the form. 
The n8n Form Trigger receives the data and starts the workflow.
An HTTP Request node in n8n sends this data in a structured JSON format to the public ngrok URL.
ngrok securely tunnels the request to the Flask API (app.py) running on the local machine.The Flask server receives the data, formats it into a pandas DataFrame, and feeds it to the loaded AI model.
The AI model returns a prediction (e.g., {"is_failure": true, "confidence": 88.06}).The Flask server sends this prediction back through the tunnel to the n8n workflow.
An IF node in n8n checks the is_failure field. If is_failure is true, the workflow proceeds to a Send Email node, which dispatches a detailed alert to a configured address. If false, the workflow ends.

# Setup and Installation
To run this project, you need to set up the Python API locally and configure the n8n workflow. 
# Prerequisites 
Python 3.8+
An n8n Cloud account (n8n.io)
A free ngrok account (ngrok.com)
1. Local Python Environment Setup
2. These steps set up the AI microservice on your computer.

# 1. Clone the repository
git clone <your-repo-url>
cd <your-repo-folder>

# 2. Create and activate a virtual environment
python -m venv .venv
.\.venv\Scripts\activate

# 3. Install the required Python libraries
pip install Flask pandas scikit-learn==1.6.1

# 4. (One-time setup) Authenticate ngrok
# Get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken
ngrok config add-authtoken <YOUR_AUTHTOKEN>
2. Running the SystemYou will need to have two terminals running simultaneously.Terminal 1: Start the AI Model Server# Make sure your virtual environment is active
.\.venv\Scripts\activate

# Run the Flask application
python app.py
This will start the server on http://127.0.0.1:5000. Leave this terminal running.Terminal 2: Start the ngrok Tunnel# Make sure your virtual environment is active
.\.venv\Scripts\activate

# Create the public tunnel to your local server
ngrok http 5000
ngrok will give you a public "Forwarding" URL (e.g., https://random-string.ngrok-free.app). Copy this URL.3. Configure the n8n WorkflowImport the workflow.json file from this repository into your n8n workspace.Open the HTTP Request node.In the URL field, paste your public ngrok Forwarding URL and add /predict at the end.Open the Send Email node and configure it with your email credentials and desired recipient address.Activate the workflow using the toggle in the top-right corner.Your system is now live! Open the URL from the Form Trigger node to submit data and test the end-to-end prediction and alerting pipeline.Acknowledgements and CreditsThis project would not be possible without the foundational work done by the data science community.The machine learning model and the initial data analysis were adapted from the "Predictive Maintenance Analysis and Modeling" notebook on Kaggle. The original work provided the dataset and the core logic for the scikit-learn pipeline.Dataset: AI4I 2020 Predictive Maintenance DatasetProper credit is given to the original author for their invaluable contribution to the machine learning aspect of this project. This project focuses on the MLOps and software engineering task of operationalizing their model.Future ImprovementsReplace ngrok: For a production environment, deploy the Flask API to a permanent cloud service (like AWS Lambda, Google Cloud Run, or Heroku) and use its stable URL.Real-time Data: Replace the n8n form with a trigger that reads data from a real-time source, such as an MQTT message broker or a database where sensor data is stored.Database Logging: Add a node to the n8n workflow to log every prediction and its inputs to a database (like PostgreSQL or Google Sheets) for tracking and analysis.Advanced Alerting: Use different notification channels based on the prediction's confidence score (e.g., low confidence sends an email, high confidence sends a PagerDuty alert).
