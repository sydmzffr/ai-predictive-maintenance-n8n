# AI-Powered Predictive Maintenance Alerting System

This project demonstrates a complete, end-to-end system that uses a machine learning model to predict equipment failure and automatically sends alerts. A user can input machine sensor data through a web form, and if the AI model predicts a high risk of failure, an alert is dispatched to the relevant personnel.

This serves as a practical example of operationalizing a data science model, moving it from a research environment (a Jupyter Notebook) into a live, interactive application using modern workflow automation and API microservices.

## Core Technologies Used

* **Machine Learning:** Python, scikit-learn, pandas
* **AI Model Serving:** Flask (as a lightweight Python microservice)
* **Workflow Automation:** n8n (Cloud version)
* **Secure Tunneling:** ngrok (to expose the local Flask API to the internet)
* **Development Environment:** Jupyter Notebook, Visual Studio Code

## Project Architecture

The system is designed with a decoupled, microservice-based architecture, allowing each component to operate independently.

1.  **User Interface (n8n Form Trigger):** A simple web form, automatically generated by n8n, serves as the user interface for inputting machine parameters.
2.  **Automation Engine (n8n Workflow):** n8n orchestrates the entire process. It receives the form submission, calls the AI service, evaluates the prediction, and triggers alerts.
3.  **Secure Tunnel (ngrok):** ngrok creates a secure public URL that forwards requests from the n8n cloud workflow to the Flask API running locally on the development machine.
4.  **AI Microservice (Flask API):** A lightweight Python server that wraps the machine learning model. It exposes a single `/predict` endpoint that accepts machine data, runs it through the model, and returns a JSON prediction.
5.  **AI Model (`.joblib` file):** The pre-trained scikit-learn pipeline, exported from a Jupyter Notebook, which contains all the necessary preprocessing steps and the trained logistic regression model.

## How It Works: Step-by-Step

1.  An engineer or operator accesses the public **n8n Form URL**.
2.  They input the current machine parameters (Temperature, Speed, Torque, etc.) and submit the form.
3.  The **n8n Form Trigger** receives the data and starts the workflow.
4.  An **HTTP Request** node in n8n sends this data in a structured JSON format to the public **ngrok URL**.
5.  **ngrok** securely tunnels the request to the **Flask API** (`app.py`) running on the local machine.
6.  The Flask server receives the data, formats it into a pandas DataFrame, and feeds it to the loaded **AI model**.
7.  The AI model returns a prediction (e.g., `{"is_failure": true, "confidence": 88.06}`).
8.  The Flask server sends this prediction back through the tunnel to the n8n workflow.
9.  An **IF** node in n8n checks the `is_failure` field.
10. If `is_failure` is `true`, the workflow proceeds to a **Send Email** node, which dispatches a detailed alert to a configured address. If `false`, the workflow ends.

## Setup and Installation

To run this project, you need to set up the Python API locally and configure the n8n workflow.

### Prerequisites

* Python 3.8+
* An n8n Cloud account ([n8n.io](https://n8n.io/))
* A free ngrok account ([ngrok.com](https://ngrok.com/))

### 1. Local Python Environment Setup

These steps set up the AI microservice on your computer.

```bash
# 1. Clone the repository
git clone <your-repo-url>
cd <your-repo-folder>

# 2. Create and activate a virtual environment
python -m venv .venv
.\.venv\Scripts\activate

# 3. Install the required Python libraries from the requirements file
pip install -r requirements.txt

# 4. (One-time setup) Authenticate ngrok
# Get your authtoken from [https://dashboard.ngrok.com/get-started/your-authtoken](https://dashboard.ngrok.com/get-started/your-authtoken)
ngrok config add-authtoken <YOUR_AUTHTOKEN>
```

### 2. Running the System

You will need to have **two terminals** running simultaneously.

**Terminal 1: Start the AI Model Server**

```bash
# Make sure your virtual environment is active
.\.venv\Scripts\activate

# Run the Flask application
python app.py
```

This will start the server on `http://127.0.0.1:5000`. Leave this terminal running.

**Terminal 2: Start the ngrok Tunnel**

```bash
# Make sure your virtual environment is active
.\.venv\Scripts\activate

# Create the public tunnel to your local server
ngrok http 5000
```

ngrok will give you a public "Forwarding" URL (e.g., `https://random-string.ngrok-free.app`). **Copy this URL.**

### 3. Configure the n8n Workflow

1.  Import the `workflow.json` file from this repository into your n8n workspace.
2.  Open the **HTTP Request** node.
3.  In the **URL** field, paste your public **ngrok Forwarding URL** and add `/predict` at the end.
4.  Open the **Send Email** node and configure it with your email credentials and desired recipient address.
5.  **Activate** the workflow using the toggle in the top-right corner.

Your system is now live! Open the URL from the **Form Trigger** node to submit data and test the end-to-end prediction and alerting pipeline.

## Acknowledgements and Credits

This project would not be possible without the foundational work done by the data science community.

* The machine learning model and the initial data analysis were adapted from the [**"Predictive Maintenance Analysis and Modeling" notebook by Brian Risk**](https://www.kaggle.com/code/devraai/predictive-maintenance-analysis-and-modeling/notebook) on Kaggle. The original work provided the dataset and the core logic for the scikit-learn pipeline.
* **Dataset:** [Machine Predictive Maintenance Classification Dataset by Shivam Bansal](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification)

Proper credit is given to the original author for their invaluable contribution to the machine learning aspect of this project. This project focuses on the MLOps and software engineering task of operationalizing their model.

## Future Improvements

* **Replace ngrok:** For a production environment, deploy the Flask API to a permanent cloud service (like AWS Lambda, Google Cloud Run, or Heroku) and use its stable URL.
* **Real-time Data:** Replace the n8n form with a trigger that reads data from a real-time source, such as an MQTT message broker or a database where sensor data is stored.
* **Database Logging:** Add a node to the n8n workflow to log every prediction and its inputs to a database (like PostgreSQL or Google Sheets) for tracking and analysis.
* **Advanced Alerting:** Use different notification channels based on the prediction's confidence score (e.g., low confidence sends an email, high confidence sends a PagerDuty alert).
